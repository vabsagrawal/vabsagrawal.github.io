{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Page This blog will help those who wants to Start Career on Performance Engineering/Testing or wants to do Interview Preparation. (This Blog is under construction)","title":"Home (This Site is Under Construction)"},{"location":"#home-page","text":"This blog will help those who wants to Start Career on Performance Engineering/Testing or wants to do Interview Preparation. (This Blog is under construction)","title":"Home Page"},{"location":"jvmarch/","text":"JVM Architecture Every Java developer knows that bytecode will be executed by JRE (Java Runtime Environment). But many doesn't know the fact that JRE is the implementation of Java Virtual Machine (JVM), which analyzes the bytecode, interprets the code, and executes it. It is very important as a developer that we should know the Architecture of the JVM, as it enables us to write code more efficiently. In this article, we will learn more dJVM Architectureeeply about the JVM architecture in Java and the different components of the JVM. What is the JVM? A Virtual Machine is a software implementation of a physical machine. Java was developed with the concept of WORA (Write Once Run Anywhere), which runs on a VM. The compiler compiles the Java file into a Java .class file, then that .class file is input into the JVM, which Loads and executes the class file. Below is a diagram of the Architecture of the JVM. JVM Architecture Diagram How Does the JVM Work? As shown in the above architecture diagram, the JVM is divided into three main subsystems: Class Loader Subsystem Runtime Data Area Execution Engine 1. Class Loader Subsystem Java's dynamic class loading functionality is handled by the class loader subsystem. It loads, links. and initializes the class file when it refers to a class for the first time at runtime, not compile time. 1.1 Loading Classes will be loaded by this component. Boot Strap class Loader, Extension class Loader, and Application class Loader are the three class loader which will help in achieving it. Boot Strap ClassLoader \u2013 Responsible for loading classes from the bootstrap classpath, nothing but rt.jar. Highest priority will be given to this loader. Extension ClassLoader \u2013 Responsible for loading classes which are inside ext folder (jre\\lib). Application ClassLoader \u2013Responsible for loading Application Level Classpath, path mentioned Environment Variable etc. The above Class Loaders will follow Delegation Hierarchy Algorithm while loading the class files. 1.2 Linking Verify \u2013 Bytecode verifier will verify whether the generated bytecode is proper or not if verification fails we will get the verification error. Prepare \u2013 For all static variables memory will be allocated and assigned with default values. Resolve \u2013 All symbolic memory references are replaced with the original references from Method Area. 1.3 Initialization This is the final phase of Class Loading, here all static variables will be assigned with the original values, and the static block will be executed. 2. Runtime Data Area The Runtime Data Area is divided into 5 major components: Method Area \u2013 All the class level data will be stored here, including static variables. There is only one method area per JVM, and it is a shared resource. Heap Area \u2013 All the Objects and their corresponding instance variables and arrays will be stored here. There is also one Heap Area per JVM. Since the Method and Heap areas share memory for multiple threads, the data stored is not thread safe. Stack Area \u2013 For every thread, a separate runtime stack will be created. For every method call, one entry will be made in the stack memory which is called as Stack Frame. All local variables will be created in the stack memory. The stack area is thread safe since it is not a shared resource. The Stack Frame is divided into three subentities: Local Variable Array \u2013 Related to the method how many local variables are involved and the corresponding values will be stored here. Operand stack \u2013 If any intermediate operation is required to perform, operand stack acts as runtime workspace to perform the operation. Frame data \u2013 All symbols corresponding to the method is stored here. In the case of any exception, the catch block information will be maintained in the frame data. PC Registers \u2013 Each thread will have separate PC Registers, to hold the address of current executing instruction once the instruction is executed the PC register will be updated with the next instruction. Native Method stacks \u2013 Native Method Stack holds native method information. For every thread, a separate native method stack will be created. 3. Execution Engine The bytecode which is assigned to the Runtime Data Area will be executed by the Execution Engine. The Execution Engine reads the bytecode and executes it piece by piece. Interpreter \u2013 The interpreter interprets the bytecode faster, but executes slowly. The disadvantage of the interpreter is that when one method is called multiple times, every time a new interpretation is required. JIT Compiler \u2013 The JIT Compiler neutralizes the disadvantage of the interpreter. The Execution Engine will be using the help of the interpreter in converting byte code, but when it finds repeated code it uses the JIT compiler, which compiles the entire bytecode and changes it to native code. This native code will be used directly for repeated method calls, which improve the performance of the system. Intermediate Code generator \u2013 Produces intermediate code Code Optimizer \u2013 Responsible for optimizing the intermediate code generated above Target Code Generator \u2013 Responsible for Generating Machine Code or Native Code Profiler \u2013 A special component, responsible for finding hotspots, i.e. whether the method is called multiple times or not. Garbage Collector: Collects and removes unreferenced objects. Garbage Collection can be triggered by calling \"System.gc()\", but the execution is not guaranteed. Garbage collection of the JVM collects the objects that are created. Java Native Interface (JNI): JNI will be interacting with the Native Method Libraries and provides the Native Libraries required for the Execution Engine. Native Method Libraries:It is a collection of the Native Libraries which is required for the Execution Engine. Refrences https://dzone.com/articles/jvm-architecture-explained","title":"JVM Architecture"},{"location":"jvmarch/#jvm-architecture","text":"Every Java developer knows that bytecode will be executed by JRE (Java Runtime Environment). But many doesn't know the fact that JRE is the implementation of Java Virtual Machine (JVM), which analyzes the bytecode, interprets the code, and executes it. It is very important as a developer that we should know the Architecture of the JVM, as it enables us to write code more efficiently. In this article, we will learn more dJVM Architectureeeply about the JVM architecture in Java and the different components of the JVM.","title":"JVM Architecture"},{"location":"jvmarch/#what-is-the-jvm","text":"A Virtual Machine is a software implementation of a physical machine. Java was developed with the concept of WORA (Write Once Run Anywhere), which runs on a VM. The compiler compiles the Java file into a Java .class file, then that .class file is input into the JVM, which Loads and executes the class file. Below is a diagram of the Architecture of the JVM. JVM Architecture Diagram","title":"What is the JVM?"},{"location":"jvmarch/#how-does-the-jvm-work","text":"As shown in the above architecture diagram, the JVM is divided into three main subsystems: Class Loader Subsystem Runtime Data Area Execution Engine 1. Class Loader Subsystem Java's dynamic class loading functionality is handled by the class loader subsystem. It loads, links. and initializes the class file when it refers to a class for the first time at runtime, not compile time. 1.1 Loading Classes will be loaded by this component. Boot Strap class Loader, Extension class Loader, and Application class Loader are the three class loader which will help in achieving it. Boot Strap ClassLoader \u2013 Responsible for loading classes from the bootstrap classpath, nothing but rt.jar. Highest priority will be given to this loader. Extension ClassLoader \u2013 Responsible for loading classes which are inside ext folder (jre\\lib). Application ClassLoader \u2013Responsible for loading Application Level Classpath, path mentioned Environment Variable etc. The above Class Loaders will follow Delegation Hierarchy Algorithm while loading the class files. 1.2 Linking Verify \u2013 Bytecode verifier will verify whether the generated bytecode is proper or not if verification fails we will get the verification error. Prepare \u2013 For all static variables memory will be allocated and assigned with default values. Resolve \u2013 All symbolic memory references are replaced with the original references from Method Area. 1.3 Initialization This is the final phase of Class Loading, here all static variables will be assigned with the original values, and the static block will be executed. 2. Runtime Data Area The Runtime Data Area is divided into 5 major components: Method Area \u2013 All the class level data will be stored here, including static variables. There is only one method area per JVM, and it is a shared resource. Heap Area \u2013 All the Objects and their corresponding instance variables and arrays will be stored here. There is also one Heap Area per JVM. Since the Method and Heap areas share memory for multiple threads, the data stored is not thread safe. Stack Area \u2013 For every thread, a separate runtime stack will be created. For every method call, one entry will be made in the stack memory which is called as Stack Frame. All local variables will be created in the stack memory. The stack area is thread safe since it is not a shared resource. The Stack Frame is divided into three subentities: Local Variable Array \u2013 Related to the method how many local variables are involved and the corresponding values will be stored here. Operand stack \u2013 If any intermediate operation is required to perform, operand stack acts as runtime workspace to perform the operation. Frame data \u2013 All symbols corresponding to the method is stored here. In the case of any exception, the catch block information will be maintained in the frame data. PC Registers \u2013 Each thread will have separate PC Registers, to hold the address of current executing instruction once the instruction is executed the PC register will be updated with the next instruction. Native Method stacks \u2013 Native Method Stack holds native method information. For every thread, a separate native method stack will be created. 3. Execution Engine The bytecode which is assigned to the Runtime Data Area will be executed by the Execution Engine. The Execution Engine reads the bytecode and executes it piece by piece. Interpreter \u2013 The interpreter interprets the bytecode faster, but executes slowly. The disadvantage of the interpreter is that when one method is called multiple times, every time a new interpretation is required. JIT Compiler \u2013 The JIT Compiler neutralizes the disadvantage of the interpreter. The Execution Engine will be using the help of the interpreter in converting byte code, but when it finds repeated code it uses the JIT compiler, which compiles the entire bytecode and changes it to native code. This native code will be used directly for repeated method calls, which improve the performance of the system. Intermediate Code generator \u2013 Produces intermediate code Code Optimizer \u2013 Responsible for optimizing the intermediate code generated above Target Code Generator \u2013 Responsible for Generating Machine Code or Native Code Profiler \u2013 A special component, responsible for finding hotspots, i.e. whether the method is called multiple times or not. Garbage Collector: Collects and removes unreferenced objects. Garbage Collection can be triggered by calling \"System.gc()\", but the execution is not guaranteed. Garbage collection of the JVM collects the objects that are created. Java Native Interface (JNI): JNI will be interacting with the Native Method Libraries and provides the Native Libraries required for the Execution Engine. Native Method Libraries:It is a collection of the Native Libraries which is required for the Execution Engine.","title":"How Does the JVM Work?"},{"location":"jvmarch/#refrences","text":"https://dzone.com/articles/jvm-architecture-explained","title":"Refrences"},{"location":"oomerrors/","text":"Understanding the OutOfMemory Errors Whenever you find yourself staring at a stacktrace with an OutOfMemoryError in it, it should all be crystal-clear. The program has got no more elbow room and is dying simply because of the lack of it. From 10,000 feet or an executive chair this might already contain too much information. But for those of you who have to build or maintain the applications and figure out why a particular error is created \u2013 we can share a bit more insight into the issue. In this post we will take a look what do different OutOfMemoryError messages actually mean. We start with the most common cases and move forward to the more interesting situations. java.lang.OutOfMemoryError: Java heap space java.lang.OutOfMemoryError: PermGen space java.lang.OutOfMemoryError: GC overhead limit exceeded java.lang.OutOfMemoryError: unable to create new native thread java.lang.OutOfMemoryError: nativeGetNewTLA java.lang.OutOfMemoryError: Requested array size exceeds VM limit java.lang.OutOfMemoryError: request bytes for . Out of swap space? java.lang.OutOfMemoryError: (Native method) java.lang.OutOfMemoryError: Java heap space We start with the one you have all seen more than you would actually like. This is the Java Virtual Machine\u2019s way to announce you that there is no more room in the virtual machine heap area. You are trying to create a new object, but the amount of memory this newly created structure is about to consume is more than the JVM has in the heap. The JVM has tried to free memory by calling full GC before throwing in the towel, but without any success. The fastest way to get rid of the symptoms is to increase the heap via -Xmx parameter. Note that both this and other recommendations in the article should be taken with a grain of salt. More often than not you just end up hiding the symptoms of the underlying problem. The next suspect is also quite common. java.lang.OutOfMemoryError: PermGen space I guess most of you have seen the java.lang.OutOfMemoryError: PermGen space during redeploys. It is pretty much the same message as the first one, but instead of the heap you are now trying to allocate memory in thePermanent Generation area. And again, you do not have enough room, so the JVM native code is kind enough to let you know about it. This message tends to disappear (for awhile) if you increase the -XX:MaxPermSize parameter. java.lang.OutOfMemoryError: GC overhead limit exceeded The third one \u2013 the java.lang.OutOfMemoryError: GC overhead limit exceeded \u2013 is a bit of a different beast. Instead of the missing heap / permgen the JVM is signaling that your application is spending too much time in garbage collection with little to show for it. By default the JVM is configured to throw this error if you are spending more than 98% of the total time in GC and less than 2% of the heap is recovered after the GC. Sounds like a perfectly good place to have the \u201cfail fast\u201d safeguard at place. In the rare cases where it makes sense to disable it, add -XX:-UseGCOverheadLimit to your startup scripts. The above three OutOfMemoryError messages make up to 98% of the cases Plumbr detects. So there is a strong chance that the remaining quintet is somewhat unknown to you. java.lang.OutOfMemoryError: unable to create new native thread is the message you will receive if the JVM is asking a new thread from the OS and the underlying OS cannot allocate a new thread anymore. This limit is very platform-dependent, so if you are curious to find out your limitations then run your own little experiment using the following code snippet. On my 64bit MacOS X running a latest JDK 7 I run into troubles when creating thread #2032. while(true){ new Thread(new Runnable(){ public void run() { try { Thread.sleep(10000000); } catch(InterruptedException e) { } } }).start(); } java.lang.OutOfMemoryError: nativeGetNewTLA is the symptom where the JVM cannot allocate new Thread Local Area. This is something you only encounter on jRockit virtual machine. If you recall, the Thread Local Area is the buffer used to efficiently allocate memory in a multi-threaded application. Each thread has its own pre-allocated buffer where all the objects instantiated by this thread are born. You will run into problems when you are creating a vast amount of objects in a heavily multi-threaded application, in case of which you might turn to tweaking the -XXtlaSizeparameter . java.lang.OutOfMemoryError: Requested array size exceeds VM limit is the message you find yourself staring at when you are trying to create an array larger than your VM limitations allow. On my 64bit Mac OS X with a recent JDK 7 build I find myself acknowledging the fact that arrays with Integer.MAX_INT-2 elements are OK, but just one more straw, namely Integer.MAX_INT-1, breaks the camel\u2019s back. On older 32-bit machines it had its benefits, limiting the array sizes to fit into the tiny heaps available back then. On modern 64bit machines it seems to create more confusion than to actually help in solving anything. java.lang.OutOfMemoryError: request bytes for . Out of swap space? This error message is thrown when the JVM fails to allocate native memory from the OS. Note that it is completely different from the standard cases where you have exhausted the heap or permgen spaces. This message tends to be displayed when you are operating close to the platform limits. As the message itself is stating you might have exceeded the amount of physical and virtual memory available. As the latter is often implemented via swapping memory to the disk, the first thing you might think of as a quick fix would be to increase the size of the swap file. But I am yet to see an application which would behave normally while swapping, so most likely this quick fix won\u2019t help you much. java.lang.OutOfMemoryError: (Native method) Now it is time to beg for help from your fellow C developers. As the message states, you are facing problems with the native code, but \u2013 unlike in the last case \u2013 the allocation failure was detected in a JNI or native method instead of the JVM code.","title":"Understanding the OutOfMemory Errors"},{"location":"oomerrors/#understanding-the-outofmemory-errors","text":"Whenever you find yourself staring at a stacktrace with an OutOfMemoryError in it, it should all be crystal-clear. The program has got no more elbow room and is dying simply because of the lack of it. From 10,000 feet or an executive chair this might already contain too much information. But for those of you who have to build or maintain the applications and figure out why a particular error is created \u2013 we can share a bit more insight into the issue. In this post we will take a look what do different OutOfMemoryError messages actually mean. We start with the most common cases and move forward to the more interesting situations. java.lang.OutOfMemoryError: Java heap space java.lang.OutOfMemoryError: PermGen space java.lang.OutOfMemoryError: GC overhead limit exceeded java.lang.OutOfMemoryError: unable to create new native thread java.lang.OutOfMemoryError: nativeGetNewTLA java.lang.OutOfMemoryError: Requested array size exceeds VM limit java.lang.OutOfMemoryError: request bytes for . Out of swap space? java.lang.OutOfMemoryError: (Native method)","title":"Understanding the OutOfMemory Errors"},{"location":"oomerrors/#javalangoutofmemoryerror-java-heap-space","text":"We start with the one you have all seen more than you would actually like. This is the Java Virtual Machine\u2019s way to announce you that there is no more room in the virtual machine heap area. You are trying to create a new object, but the amount of memory this newly created structure is about to consume is more than the JVM has in the heap. The JVM has tried to free memory by calling full GC before throwing in the towel, but without any success. The fastest way to get rid of the symptoms is to increase the heap via -Xmx parameter. Note that both this and other recommendations in the article should be taken with a grain of salt. More often than not you just end up hiding the symptoms of the underlying problem. The next suspect is also quite common.","title":"java.lang.OutOfMemoryError: Java heap space"},{"location":"oomerrors/#javalangoutofmemoryerror-permgen-space","text":"I guess most of you have seen the java.lang.OutOfMemoryError: PermGen space during redeploys. It is pretty much the same message as the first one, but instead of the heap you are now trying to allocate memory in thePermanent Generation area. And again, you do not have enough room, so the JVM native code is kind enough to let you know about it. This message tends to disappear (for awhile) if you increase the -XX:MaxPermSize parameter.","title":"java.lang.OutOfMemoryError: PermGen space"},{"location":"oomerrors/#javalangoutofmemoryerror-gc-overhead-limit-exceeded","text":"The third one \u2013 the java.lang.OutOfMemoryError: GC overhead limit exceeded \u2013 is a bit of a different beast. Instead of the missing heap / permgen the JVM is signaling that your application is spending too much time in garbage collection with little to show for it. By default the JVM is configured to throw this error if you are spending more than 98% of the total time in GC and less than 2% of the heap is recovered after the GC. Sounds like a perfectly good place to have the \u201cfail fast\u201d safeguard at place. In the rare cases where it makes sense to disable it, add -XX:-UseGCOverheadLimit to your startup scripts. The above three OutOfMemoryError messages make up to 98% of the cases Plumbr detects. So there is a strong chance that the remaining quintet is somewhat unknown to you. java.lang.OutOfMemoryError: unable to create new native thread is the message you will receive if the JVM is asking a new thread from the OS and the underlying OS cannot allocate a new thread anymore. This limit is very platform-dependent, so if you are curious to find out your limitations then run your own little experiment using the following code snippet. On my 64bit MacOS X running a latest JDK 7 I run into troubles when creating thread #2032. while(true){ new Thread(new Runnable(){ public void run() { try { Thread.sleep(10000000); } catch(InterruptedException e) { } } }).start(); }","title":"java.lang.OutOfMemoryError: GC overhead limit exceeded"},{"location":"oomerrors/#javalangoutofmemoryerror-nativegetnewtla","text":"is the symptom where the JVM cannot allocate new Thread Local Area. This is something you only encounter on jRockit virtual machine. If you recall, the Thread Local Area is the buffer used to efficiently allocate memory in a multi-threaded application. Each thread has its own pre-allocated buffer where all the objects instantiated by this thread are born. You will run into problems when you are creating a vast amount of objects in a heavily multi-threaded application, in case of which you might turn to tweaking the -XXtlaSizeparameter .","title":"java.lang.OutOfMemoryError: nativeGetNewTLA"},{"location":"oomerrors/#javalangoutofmemoryerror-requested-array-size-exceeds-vm-limit","text":"is the message you find yourself staring at when you are trying to create an array larger than your VM limitations allow. On my 64bit Mac OS X with a recent JDK 7 build I find myself acknowledging the fact that arrays with Integer.MAX_INT-2 elements are OK, but just one more straw, namely Integer.MAX_INT-1, breaks the camel\u2019s back. On older 32-bit machines it had its benefits, limiting the array sizes to fit into the tiny heaps available back then. On modern 64bit machines it seems to create more confusion than to actually help in solving anything.","title":"java.lang.OutOfMemoryError: Requested array size exceeds VM limit"},{"location":"oomerrors/#javalangoutofmemoryerror-request-bytes-for-out-of-swap-space","text":"This error message is thrown when the JVM fails to allocate native memory from the OS. Note that it is completely different from the standard cases where you have exhausted the heap or permgen spaces. This message tends to be displayed when you are operating close to the platform limits. As the message itself is stating you might have exceeded the amount of physical and virtual memory available. As the latter is often implemented via swapping memory to the disk, the first thing you might think of as a quick fix would be to increase the size of the swap file. But I am yet to see an application which would behave normally while swapping, so most likely this quick fix won\u2019t help you much.","title":"java.lang.OutOfMemoryError: request  bytes for . Out of swap space?"},{"location":"oomerrors/#javalangoutofmemoryerror-native-method","text":"Now it is time to beg for help from your fellow C developers. As the message states, you are facing problems with the native code, but \u2013 unlike in the last case \u2013 the allocation failure was detected in a JNI or native method instead of the JVM code.","title":"java.lang.OutOfMemoryError:   (Native method)"},{"location":"oops/","text":"Java oops Concepts Encapsulation Encapsulation is one of the four fundamental OOP concepts. The other three are inheritance, polymorphism, and abstraction. Encapsulation in Java is a mechanism of wrapping the data (variables) and code acting on the data (methods) together as as single unit. In encapsulation the variables of a class will be hidden from other classes, and can be accessed only through the methods of their current class, therefore it is also known as data hiding. To achieve encapsulation in Java : Declare the variables of a class as private. Provide public setter and getter methods to modify and view the variables values. Inheritance Inheritance can be defined as the process where one class acquires the properties (methods and fields) of another. With the use of inheritance the information is made manageable in a hierarchical order. The class which inherits the properties of other is known as subclass (derived class, child class) and the class whose properties are inherited is known as superclass (base class, parent class). extends is the keyword used to inherit the properties of a class. Below given is the syntax of extends keyword. Polymorphism Polymorphism is the concept where an object behaves differently in different situations. There are two types of polymorphism \u2013 compile time polymorphism and runtime polymorphism. Compile time polymorphism is achieved by method overloading. For example, we can have a class as below. public class Circle { public void draw(){ System.out.println(\"Drwaing circle with default color Black and diameter 1 cm.\"); } public void draw(int diameter){ System.out.println(\"Drwaing circle with default color Black and diameter\"+diameter+\" cm.\"); } public void draw(int diameter, String color){ System.out.println(\"Drwaing circle with color\"+color+\" and diameter\"+diameter+\" cm.\"); } } Here we have multiple draw methods but they have different behavior. This is a case of method overloading because all the methods name is same and arguments are different. Here compiler will be able to identify the method to invoke at compile time, hence it\u2019s called compile time polymorphism. Runtime polymorphism is implemented when we have \u201cIS-A\u201d relationship between objects. This is also called as method overriding because subclass has to override the superclass method for runtime polymorphism. If we are working in terms of superclass, the actual implementation class is decided at runtime. Compiler is not able to decide which class method will be invoked. This decision is done at runtime, hence the name as runtime polymorphism or dynamic method dispatch. package com.test; public interface Shape { public void draw(); } package com.test; public class Circle implements Shape{ @Override public void draw(){ System.out.println(\"Drwaing circle\"); } } package com.test; public class Square implements Shape { @Override public void draw() { System.out.println(\"Drawing Square\"); } } Shape is the superclass and there are two subclasses Circle and Square. Below is an example of runtime polymorphism. Shape sh = new Circle(); sh.draw(); Shape sh1 = getShape(); //some third party logic to determine shape sh1.draw(); In above examples, java compiler don\u2019t know the actual implementation class of Shape that will be used at runtime, hence runtime polymorphism. Abstraction In Object oriented programming Abstraction is a process process of hiding the implementation details from the user, only the functionality will be provided to the user. In other words user will have the information on what the object does instead of how it does it. In Java Abstraction is achieved using Abstract classes and Interfaces. A class which contains the abstract keyword in its declaration is known as abstract class. An interface is a reference type in Java, it is similar to class, it is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface. Along with abstract methods an interface may also contain constants, default methods, static methods, and nested types. Method bodies exist only for default methods and static methods. Writing an interface is similar to writing a class. But a class describes the attributes and behaviours of an object. And an interface contains behaviours that a class implements. Unless the class that implements the interface is abstract, all the methods of the interface need to be defined in the class. An interface is similar to a class in the following ways: An interface can contain any number of methods. An interface is written in a file with a .java extension, with the name of the interface matching the name of the file. The byte code of an interface appears in a .class file. Interfaces appear in packages, and their corresponding bytecode file must be in a directory structure that matches the package name. However, an interface is different from a class in several ways, including: You cannot instantiate an interface. An interface does not contain any constructors. All of the methods in an interface are abstract. An interface cannot contain instance fields. The only fields that can appear in an interface must be declared both static and final. An interface is not extended by a class; it is implemented by a class. An interface can extend multiple interfaces. Refrences https://www.google.com https://www.tutorialspoint.com","title":"Java oops Concepts"},{"location":"oops/#java-oops-concepts","text":"","title":"Java oops Concepts"},{"location":"oops/#encapsulation","text":"Encapsulation is one of the four fundamental OOP concepts. The other three are inheritance, polymorphism, and abstraction. Encapsulation in Java is a mechanism of wrapping the data (variables) and code acting on the data (methods) together as as single unit. In encapsulation the variables of a class will be hidden from other classes, and can be accessed only through the methods of their current class, therefore it is also known as data hiding. To achieve encapsulation in Java : Declare the variables of a class as private. Provide public setter and getter methods to modify and view the variables values.","title":"Encapsulation"},{"location":"oops/#inheritance","text":"Inheritance can be defined as the process where one class acquires the properties (methods and fields) of another. With the use of inheritance the information is made manageable in a hierarchical order. The class which inherits the properties of other is known as subclass (derived class, child class) and the class whose properties are inherited is known as superclass (base class, parent class). extends is the keyword used to inherit the properties of a class. Below given is the syntax of extends keyword.","title":"Inheritance"},{"location":"oops/#polymorphism","text":"Polymorphism is the concept where an object behaves differently in different situations. There are two types of polymorphism \u2013 compile time polymorphism and runtime polymorphism. Compile time polymorphism is achieved by method overloading. For example, we can have a class as below. public class Circle { public void draw(){ System.out.println(\"Drwaing circle with default color Black and diameter 1 cm.\"); } public void draw(int diameter){ System.out.println(\"Drwaing circle with default color Black and diameter\"+diameter+\" cm.\"); } public void draw(int diameter, String color){ System.out.println(\"Drwaing circle with color\"+color+\" and diameter\"+diameter+\" cm.\"); } } Here we have multiple draw methods but they have different behavior. This is a case of method overloading because all the methods name is same and arguments are different. Here compiler will be able to identify the method to invoke at compile time, hence it\u2019s called compile time polymorphism. Runtime polymorphism is implemented when we have \u201cIS-A\u201d relationship between objects. This is also called as method overriding because subclass has to override the superclass method for runtime polymorphism. If we are working in terms of superclass, the actual implementation class is decided at runtime. Compiler is not able to decide which class method will be invoked. This decision is done at runtime, hence the name as runtime polymorphism or dynamic method dispatch. package com.test; public interface Shape { public void draw(); } package com.test; public class Circle implements Shape{ @Override public void draw(){ System.out.println(\"Drwaing circle\"); } } package com.test; public class Square implements Shape { @Override public void draw() { System.out.println(\"Drawing Square\"); } } Shape is the superclass and there are two subclasses Circle and Square. Below is an example of runtime polymorphism. Shape sh = new Circle(); sh.draw(); Shape sh1 = getShape(); //some third party logic to determine shape sh1.draw(); In above examples, java compiler don\u2019t know the actual implementation class of Shape that will be used at runtime, hence runtime polymorphism.","title":"Polymorphism"},{"location":"oops/#abstraction","text":"In Object oriented programming Abstraction is a process process of hiding the implementation details from the user, only the functionality will be provided to the user. In other words user will have the information on what the object does instead of how it does it. In Java Abstraction is achieved using Abstract classes and Interfaces. A class which contains the abstract keyword in its declaration is known as abstract class. An interface is a reference type in Java, it is similar to class, it is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface. Along with abstract methods an interface may also contain constants, default methods, static methods, and nested types. Method bodies exist only for default methods and static methods. Writing an interface is similar to writing a class. But a class describes the attributes and behaviours of an object. And an interface contains behaviours that a class implements. Unless the class that implements the interface is abstract, all the methods of the interface need to be defined in the class. An interface is similar to a class in the following ways: An interface can contain any number of methods. An interface is written in a file with a .java extension, with the name of the interface matching the name of the file. The byte code of an interface appears in a .class file. Interfaces appear in packages, and their corresponding bytecode file must be in a directory structure that matches the package name. However, an interface is different from a class in several ways, including: You cannot instantiate an interface. An interface does not contain any constructors. All of the methods in an interface are abstract. An interface cannot contain instance fields. The only fields that can appear in an interface must be declared both static and final. An interface is not extended by a class; it is implemented by a class. An interface can extend multiple interfaces.","title":"Abstraction"},{"location":"oops/#refrences","text":"https://www.google.com https://www.tutorialspoint.com","title":"Refrences"},{"location":"page1/","text":"Page1","title":"Page1"},{"location":"page1/#page1","text":"","title":"Page1"},{"location":"rssvsz/","text":"Analogy-1 RSS is the Resident Set Size and is used to show how much memory is allocated to that process and is in RAM. It does not include memory that is swapped out. It does include memory from shared libraries as long as the pages from those libraries are actually in memory. It does include all stack and heap memory. VSZ is the Virtual Memory Size. It includes all memory that the process can access, including memory that is swapped out, memory that is allocated, but not used, and memory that is from shared libraries. So if process A has a 500K binary and is linked to 2500K of shared libraries, has 200K of stack/heap allocations of which 100K is actually in memory (rest is swapped or unused), and it has only actually loaded 1000K of the shared libraries and 400K of its own binary then: RSS: 400K + 1000K + 100K = 1500K VSZ: 500K + 2500K + 200K = 3200K Since part of the memory is shared, many processes may use it, so if you add up all of the RSS values you can easily end up with more space than your system has. The memory that is allocated also may not be in RSS until it is actually used by the program. So if your program allocated a bunch of memory up front, then uses it over time, you could see RSS going up and VSZ staying the same. There is also PSS (proportional set size). This is a newer measure which tracks the shared memory as a proportion used by the current process. So if there were two processes using the same shared library from before: PSS: 400K + (1000K/2) + 100K = 400K + 500K + 100K = 1000K Threads all share the same address space, so the RSS, VSZ and PSS for each thread is identical to all of the other threads in the process. Use ps or top to view this information in linux/unix. Analogy-2 This article explains three indicators that can possibly be used to measure the memory consumption of a single process on Linux. VSZ (Virtual Memory Size), RSS (Resident Set Size), and PSS (Proportional Set Size). Although this will lack accuracy, let us consider an allegory to get the idea. There are three people sharing a room. We will consider each person to represent a process, and living expenses to represent memory consumption. Measuring the memory consumption of a single process will be represented as calculating the total living expense for one person in this allegory. Each person has their own cell phone line that is not being shared. All three indicators, VSZ, RSS, and PSS, will count the cell phone bills as each persons living expense individually, and there is no problem with this. The shared room comes with a garage space that can be used if they pay for it, but they all don't drive and they are not using it. However, VSZ will count the entire garage space cost as each persons living expense even though they are not using it. VSZ, therefore, represents the total living expense when they spend on every possible thing regardless of the actual usage. RSS and PSS only count expenses that are actually being used, and therefore, they will not count the garage space cost because it is not being used. Since they are sharing the internet connection and the cable TV, they split up those bills. However, RSS will count the entire amount of the internet connection and cable TV as each persons living expense, even though they are sharing it and splitting up the bill. The idea of RSS is to calculate living expenses as it was not shared with anybody else. PSS will only count one third of the internet connection and cable TV bill as each persons living expense, because they are sharing it. This is more reasonable than RSS since it is considers the fact that they are sharing it. Let's make the allegory a little bit more complicated in order to understand the limitations of PSS. One person is always on the internet and doesn't watch TV that much. Hence, that person pays 50% of the internet connection bill and 20% of the cable TV bill upon agreement. PSS, however, cannot handle situations like this. It will simply calculate one third of the internet connection bill and cable TV bill as each persons living expense. Using PSS is what I consider most reasonable. However, there are limitations and there are also situations where RSS may work better. RSS is reasonable when you want to know the total living expense when you move out and live on your own. Refrences https://www.google.com https://web.archive.org/web/20120520221529/http://emilics.com/blog/article/mconsumption.html http://manpages.ubuntu.com/manpages/en/man1/ps.1.html https://web.archive.org/web/20120520221529/http://emilics.com/blog/article/mconsumption.html","title":"Memory RSS vs VSZ"},{"location":"rssvsz/#analogy-1","text":"RSS is the Resident Set Size and is used to show how much memory is allocated to that process and is in RAM. It does not include memory that is swapped out. It does include memory from shared libraries as long as the pages from those libraries are actually in memory. It does include all stack and heap memory. VSZ is the Virtual Memory Size. It includes all memory that the process can access, including memory that is swapped out, memory that is allocated, but not used, and memory that is from shared libraries. So if process A has a 500K binary and is linked to 2500K of shared libraries, has 200K of stack/heap allocations of which 100K is actually in memory (rest is swapped or unused), and it has only actually loaded 1000K of the shared libraries and 400K of its own binary then: RSS: 400K + 1000K + 100K = 1500K VSZ: 500K + 2500K + 200K = 3200K Since part of the memory is shared, many processes may use it, so if you add up all of the RSS values you can easily end up with more space than your system has. The memory that is allocated also may not be in RSS until it is actually used by the program. So if your program allocated a bunch of memory up front, then uses it over time, you could see RSS going up and VSZ staying the same. There is also PSS (proportional set size). This is a newer measure which tracks the shared memory as a proportion used by the current process. So if there were two processes using the same shared library from before: PSS: 400K + (1000K/2) + 100K = 400K + 500K + 100K = 1000K Threads all share the same address space, so the RSS, VSZ and PSS for each thread is identical to all of the other threads in the process. Use ps or top to view this information in linux/unix.","title":"Analogy-1"},{"location":"rssvsz/#analogy-2","text":"This article explains three indicators that can possibly be used to measure the memory consumption of a single process on Linux. VSZ (Virtual Memory Size), RSS (Resident Set Size), and PSS (Proportional Set Size). Although this will lack accuracy, let us consider an allegory to get the idea. There are three people sharing a room. We will consider each person to represent a process, and living expenses to represent memory consumption. Measuring the memory consumption of a single process will be represented as calculating the total living expense for one person in this allegory. Each person has their own cell phone line that is not being shared. All three indicators, VSZ, RSS, and PSS, will count the cell phone bills as each persons living expense individually, and there is no problem with this. The shared room comes with a garage space that can be used if they pay for it, but they all don't drive and they are not using it. However, VSZ will count the entire garage space cost as each persons living expense even though they are not using it. VSZ, therefore, represents the total living expense when they spend on every possible thing regardless of the actual usage. RSS and PSS only count expenses that are actually being used, and therefore, they will not count the garage space cost because it is not being used. Since they are sharing the internet connection and the cable TV, they split up those bills. However, RSS will count the entire amount of the internet connection and cable TV as each persons living expense, even though they are sharing it and splitting up the bill. The idea of RSS is to calculate living expenses as it was not shared with anybody else. PSS will only count one third of the internet connection and cable TV bill as each persons living expense, because they are sharing it. This is more reasonable than RSS since it is considers the fact that they are sharing it. Let's make the allegory a little bit more complicated in order to understand the limitations of PSS. One person is always on the internet and doesn't watch TV that much. Hence, that person pays 50% of the internet connection bill and 20% of the cable TV bill upon agreement. PSS, however, cannot handle situations like this. It will simply calculate one third of the internet connection bill and cable TV bill as each persons living expense. Using PSS is what I consider most reasonable. However, there are limitations and there are also situations where RSS may work better. RSS is reasonable when you want to know the total living expense when you move out and live on your own.","title":"Analogy-2"},{"location":"rssvsz/#refrences","text":"https://www.google.com https://web.archive.org/web/20120520221529/http://emilics.com/blog/article/mconsumption.html http://manpages.ubuntu.com/manpages/en/man1/ps.1.html https://web.archive.org/web/20120520221529/http://emilics.com/blog/article/mconsumption.html","title":"Refrences"},{"location":"sub-page1/","text":"sub-page1","title":"sub-page1"},{"location":"sub-page1/#sub-page1","text":"","title":"sub-page1"}]}